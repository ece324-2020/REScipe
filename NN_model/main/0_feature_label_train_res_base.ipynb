{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_feature_label_train_res_base.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-KKFkrw0dYu","executionInfo":{"status":"ok","timestamp":1606673004749,"user_tz":-480,"elapsed":1968,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}},"outputId":"81215632-bfde-405b-e652-abb1451c7e83"},"source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","#!ls /content/gdrive"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eZPm7mqP1i8l","executionInfo":{"status":"ok","timestamp":1606673007407,"user_tz":-480,"elapsed":666,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}}},"source":["# configuration\n","path = \"/content/drive/MyDrive/Colab Notebooks/Project_REScipe/training/\""],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbdCgcJRPorS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606673011296,"user_tz":-480,"elapsed":1130,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}},"outputId":"d04d5f3b-1993-425a-ad82-f3ca7895763b"},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n","from scipy.spatial.distance import cosine\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.utils.data as Data\n","from torch.utils.data import DataLoader\n","import torchvision\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","import matplotlib.pyplot as plt\n","import PIL\n","from PIL import Image\n","\n","if torch.cuda.is_available():\n","  print(torch.cuda.is_available())\n","  torch.set_default_tensor_type(torch.cuda.FloatTensor)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"heOovFGf8KJA"},"source":["===================== A =====================\n","\n","Load train and valid dataset from pickle files into panda dataframe."]},{"cell_type":"code","metadata":{"id":"qeF6CKmV8eZk"},"source":["# training resnet\n","pd.set_option('display.max_columns', None)\n","\n","t0 = pd.read_pickle(path + \"resnet_train_dataframe0.plk\")\n","print('# images in df0:', len(t0))\n","t1 = pd.read_pickle(path + \"resnet_train_dataframe1.plk\")\n","print('# images in df1:', len(t1))\n","t2 = pd.read_pickle(path + \"resnet_train_dataframe2.plk\")\n","print('# images in df2:', len(t2))\n","t3 = pd.read_pickle(path + \"resnet_train_dataframe3.plk\")\n","print('# images in df3:', len(t3), end='\\n\\n')\n","\n","train_dataframe = pd.concat([t0,t1,t2,t3], ignore_index=True)\n","train_dataframe = train_dataframe.drop(columns=['code'])\n","print('dataframe shape:', train_dataframe.shape, end='\\n\\n')\n","\n","print('MLP input shape:', (train_dataframe.iloc[0][0]).shape)\n","print('MLP output shape:', (train_dataframe.iloc[0][1]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iBQCtWJM1Hcu"},"source":["# validation resnet\n","v0 = pd.read_pickle(path + \"resnet_val_dataframe0.plk\")\n","print('# images in df0:', len(v0))\n","v1 = pd.read_pickle(path + \"resnet_val_dataframe1.plk\")\n","print('# images in df1:', len(v1))\n","v2 = pd.read_pickle(path + \"resnet_val_dataframe2.plk\")\n","print('# images in df2:', len(v2))\n","v3 = pd.read_pickle(path + \"resnet_val_dataframe3.plk\")\n","print('# images in df3:', len(v3))\n","\n","valid_dataframe = pd.concat([v0,v1,v2,v3], ignore_index=True)\n","valid_dataframe = valid_dataframe.drop(columns=['code'])\n","print('dataframe shape:', valid_dataframe.shape, end='\\n\\n')\n","\n","print('MLP input shape:', (valid_dataframe.iloc[0][0]).shape)\n","print('MLP output shape:', (valid_dataframe.iloc[0][1]).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VlBhcRY6_7_H"},"source":["===================== B =====================\n","\n","Check similarity between MLP inputs from outputs of Resnet."]},{"cell_type":"code","metadata":{"id":"5LqSWIuSUhPs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606673741786,"user_tz":-480,"elapsed":696,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}},"outputId":"ba7c7669-6eb1-41bf-b988-432d6b8be7b0"},"source":["## This doesn't work, it assume we have 300 distinct labels but apparently that isnt the case\n","# print(len(valid_dataframe[\"label\"].values))\n","# label_classes = []\n","# def arreqclose_in_list(myarr, list_arrays):\n","#     return next((True for elem in list_arrays if elem.size == myarr.size and np.allclose(elem, myarr)), False)\n","\n","# for i in range(len(valid_dataframe[\"label\"].values)):\n","#   check = arreqclose_in_list(valid_dataframe[\"label\"].values[i], label_classes)\n","#   if not(check):\n","#     label_classes.append(valid_dataframe[\"label\"].values[i])\n","#     print(i,len(label_classes))\n","#   if i % 1000 == 0:\n","#     print(i)\n","\n","## Cosine Similarity Test for first two set of similar images (5 images in each set)\n","print(valid_dataframe.columns, end='\\n\\n')\n","print('cos_similarity', 'e_distance', 'index (cmp with next)', sep='\\t')\n","for i in range(10):\n","  point1 = valid_dataframe[\"resnet_features\"].values[i]\n","  point2 = valid_dataframe[\"resnet_features\"].values[i+1]\n","  sim = cosine_similarity(point1,point2)\n","  dist = np.linalg.norm(point1 - point2) \n","  print(sim, dist, i, sep='\\t')"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Index(['resnet_features', 'label'], dtype='object')\n","\n","cos_similarity\te_distance\tindex (cmp with next)\n","[[0.99545217]]\t2.0607522\t0\n","[[0.99532866]]\t2.094894\t1\n","[[0.9956309]]\t2.028304\t2\n","[[0.9959206]]\t1.9654641\t3\n","[[0.99534404]]\t2.1097574\t4\n","[[0.99569434]]\t2.0096145\t5\n","[[0.99562407]]\t2.021868\t6\n","[[0.99579453]]\t1.9653133\t7\n","[[0.9956789]]\t1.9935576\t8\n","[[0.995701]]\t2.004184\t9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fJSApQ_KDTJH"},"source":["===================== C =====================\n","\n","Load test dataset from pickle files into panda dataframe."]},{"cell_type":"code","metadata":{"id":"84Mjtop61Kxn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606673942578,"user_tz":-480,"elapsed":680,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}},"outputId":"366cab19-49a2-435b-c6be-af65d6b52b66"},"source":["t = pd.read_pickle(path + \"resnet_test_dataframe.plk\")\n","#print('# images in df:', len(t))\n","#print(t, end='\\n')\n","\n","test_dataframe = pd.concat([t], ignore_index=True)\n","test_dataframe = test_dataframe.drop(columns=['code'])\n","print('dataframe shape:', test_dataframe.shape, end='\\n\\n')\n","\n","print('MLP input shape:', (test_dataframe.iloc[0][0]).shape)\n","print('MLP output shape:', (test_dataframe.iloc[0][1]).shape)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["dataframe shape: (9090, 2)\n","\n","MLP input shape: (1, 2048)\n","MLP output shape: (300,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HfWj0T3YuLR_"},"source":["===================== C-Addition =====================\n","\n","Visualizing data distribution."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wteYTDLKuK_I","executionInfo":{"status":"ok","timestamp":1606673946873,"user_tz":-480,"elapsed":1144,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}},"outputId":"627bcfb3-1cbe-4979-eacb-32f87a85f3fd"},"source":["train_pd = pd.concat([t0, t1, t2, t3], ignore_index=True)\n","print('# images in training set:', len(train_pd))\n","print(train_pd, end='\\n\\n\\n')\n","valid_pd = pd.concat([v0, v1, v2, v3], ignore_index=True)\n","print('# images in validation set:', len(valid_pd))\n","print(valid_pd, end='\\n\\n\\n')\n","test_pd = pd.concat([t], ignore_index=True)\n","print('# images in testing set:', len(test_pd))\n","print(test_pd)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["# images in training set: 200000\n","                                          resnet_features  \\\n","0       [[0.3849878, 0.56532997, 0.48705465, 0.3911603...   \n","1       [[0.3929283, 0.5334326, 0.5158059, 0.3787949, ...   \n","2       [[0.3686152, 0.58579177, 0.45799288, 0.4308609...   \n","3       [[0.34291622, 0.56042266, 0.45366722, 0.400371...   \n","4       [[0.36115068, 0.53820133, 0.4652329, 0.3929110...   \n","...                                                   ...   \n","199995  [[0.40786082, 0.5255577, 0.4641556, 0.41342828...   \n","199996  [[0.37225196, 0.56219035, 0.44345364, 0.348088...   \n","199997  [[0.39488277, 0.5134853, 0.44654036, 0.4102318...   \n","199998  [[0.39580283, 0.56715083, 0.48746654, 0.385420...   \n","199999  [[0.33728877, 0.5174161, 0.43714473, 0.4135678...   \n","\n","                                                    label    code  \n","0       [0.001109877913429523, 0.001109877913429523, 0...   70006  \n","1       [0.001109877913429523, 0.001109877913429523, 0...   70006  \n","2       [0.001109877913429523, 0.001109877913429523, 0...   70006  \n","3       [0.001109877913429523, 0.001109877913429523, 0...   70006  \n","4       [0.001109877913429523, 0.001109877913429523, 0...   70006  \n","...                                                   ...     ...  \n","199995  [0.0033222591362126242, 0.0033222591362126242,...  266511  \n","199996  [0.0033222591362126242, 0.0033222591362126242,...  266511  \n","199997  [0.0033222591362126242, 0.0033222591362126242,...  266511  \n","199998  [0.0033222591362126242, 0.0033222591362126242,...  266511  \n","199999  [0.0033222591362126242, 0.0033222591362126242,...  266511  \n","\n","[200000 rows x 3 columns]\n","\n","\n","# images in validation set: 40000\n","                                         resnet_features  \\\n","0      [[0.3623722, 0.48193905, 0.43886885, 0.3941442...   \n","1      [[0.36151594, 0.5402268, 0.49298325, 0.4231605...   \n","2      [[0.37522918, 0.5902126, 0.5167053, 0.41194558...   \n","3      [[0.36588845, 0.61720884, 0.4358776, 0.3872864...   \n","4      [[0.36618167, 0.50886345, 0.4819845, 0.4249065...   \n","...                                                  ...   \n","39995  [[0.34230182, 0.52472156, 0.43094298, 0.425484...   \n","39996  [[0.3890288, 0.5826305, 0.51688343, 0.3790824,...   \n","39997  [[0.30306932, 0.5098857, 0.46076334, 0.4192525...   \n","39998  [[0.3971831, 0.5641648, 0.49273685, 0.43840054...   \n","39999  [[0.39621493, 0.4939858, 0.44962534, 0.4285536...   \n","\n","                                                   label    code  \n","0      [0.001109877913429523, 0.001109877913429523, 0...   70006  \n","1      [0.0016639162998775608, 0.0016639162998775608,...   70012  \n","2      [0.0016638935108153079, 0.0016638935108153079,...   70014  \n","3      [0.0033222591362126247, 0.0033222591362126247,...   70019  \n","4      [0.0033222591362126247, 0.0033222591362126247,...   70032  \n","...                                                  ...     ...  \n","39995  [0.003111286983118562, 0.003111286983118562, 0...  266473  \n","39996  [0.003322259136212625, 0.003322259136212625, 0...  266474  \n","39997  [0.0033222591362126242, 0.0033222591362126242,...  266475  \n","39998  [0.0033222591362126247, 0.0033222591362126247,...  266510  \n","39999  [0.0033222591362126242, 0.0033222591362126242,...  266511  \n","\n","[40000 rows x 3 columns]\n","\n","\n","# images in testing set: 9090\n","                                        resnet_features  \\\n","0     [[0.33581847, 0.5185517, 0.4552609, 0.38119817...   \n","1     [[0.33866388, 0.5399615, 0.47846508, 0.3511671...   \n","2     [[0.33708882, 0.5778944, 0.48544037, 0.4082099...   \n","3     [[0.31872, 0.60966516, 0.43710068, 0.35379463,...   \n","4     [[0.41543022, 0.5419319, 0.45780173, 0.3661607...   \n","...                                                 ...   \n","9085  [[0.37172443, 0.5861802, 0.47876903, 0.3822791...   \n","9086  [[0.36807737, 0.5949055, 0.49201164, 0.3982288...   \n","9087  [[0.3466755, 0.58012795, 0.4615528, 0.42040485...   \n","9088  [[0.32109177, 0.5927376, 0.4270323, 0.3573679,...   \n","9089  [[0.3695631, 0.6369191, 0.47295383, 0.37802798...   \n","\n","                                                  label    code  \n","0     [0.0016638935108153076, 0.0016638935108153076,...  266512  \n","1     [0.0016638935108153076, 0.0016638935108153076,...  266512  \n","2     [0.0016638935108153076, 0.0016638935108153076,...  266512  \n","3     [0.0016638935108153076, 0.0016638935108153076,...  266512  \n","4     [0.0016638935108153076, 0.0016638935108153076,...  266512  \n","...                                                 ...     ...  \n","9085  [0.0033222591362126242, 0.0033222591362126242,...  269899  \n","9086  [0.0033222591362126242, 0.0033222591362126242,...  269899  \n","9087  [0.0033222591362126242, 0.0033222591362126242,...  269899  \n","9088  [0.0033222591362126242, 0.0033222591362126242,...  269899  \n","9089  [0.0033222591362126242, 0.0033222591362126242,...  269899  \n","\n","[9090 rows x 3 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wi8CqdI7EAbr"},"source":["===================== D =====================\n","\n","Define PyTorch dataset with this dataset."]},{"cell_type":"code","metadata":{"id":"TLgM_lPx1M_B","executionInfo":{"status":"ok","timestamp":1606673967899,"user_tz":-480,"elapsed":667,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}}},"source":["class Dataset(torch.utils.data.Dataset):\n","  def __init__(self, X, y):\n","    self.X = X\n","    self.y = y\n","\n","  def __len__(self):\n","    return len(self.X)\n","\n","  def __getitem__(self, index):\n","    if torch.is_tensor(index):\n","      index = index.tolist()\n","    X = self.X[index]\n","    y = self.y[index]\n","    return X,y"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V17PpN124uAt"},"source":["===================== E =====================\n","\n","Other helper functions:\n","\n","(1) printing plots\n","\n","(2) evaluating model\n","\n","(3) accuracy function"]},{"cell_type":"code","metadata":{"id":"Tw1OKPbQSLx0","executionInfo":{"status":"ok","timestamp":1606673977780,"user_tz":-480,"elapsed":699,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}}},"source":["# printing plot\n","def plot_result(x=None, y=[], title=[], x_axis=\"\", y_axis=\"\", plot_title=\"\"):\n","  plt.figure()\n","  i = 0\n","  for accu in y:\n","    plt.plot(x, accu, label=title[i])\n","    i += 1\n","  plt.legend(loc='best')\n","  plt.xlabel(x_axis)\n","  plt.ylabel(y_axis)\n","  plt.title(plot_title)\n","  plt.ylim(0)\n","  plt.show()\n","\n","# evaluating a model (model, loss function, valid/test dataloader)\n","def evaluate(model, loss_fnc, val_iter):\n","  model.eval()\n","\n","  running_loss = 0.0\n","  running_correct = 0.0\n","  count = 0.0\n","  for data in val_iter:\n","    X, y = data\n","    ## ===================== CUDA version\n","    # For Resnet:\n","    X = torch.squeeze(X,1)\n","    X = X.type(torch.cuda.FloatTensor)\n","    y = y.type(torch.cuda.FloatTensor)\n","    ## =====================\n","    output = model(X)\n","    loss = loss_fnc(output, y)\n","    running_loss += loss.item() * len(y)\n","    running_correct += accurate(output, y)\n","    count += len(y)\n","  return running_correct/count, running_loss/count\n","\n","# accuracy function: return number of \"correct\" prediction\n","def accurate(pred, label):\n","  correct = 0\n","  for i in range(pred.shape[0]): # get the length, maybe use len\n","    f = pred[i].cpu().detach().numpy().reshape(1,-1)\n","    l = label[i].cpu().detach().numpy().reshape(1,-1)\n","    similarity = cosine_similarity(f,l)\n","    if similarity > 0.9:\n","      correct += 1\n","  return correct"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDKgQgu6fCze"},"source":["===================== F =====================\n","\n","Resnet MLP model and training setup (hyperparameters):"]},{"cell_type":"code","metadata":{"id":"UZnS-Jy12X0c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606674279119,"user_tz":-480,"elapsed":851,"user":{"displayName":"Jiakai Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhggZfXntQzGYk4jDX-Ii4T4UGlxKidkZPx4_dphA=s64","userId":"17495190027926712228"}},"outputId":"f59710f8-cb49-42f7-950f-b3bd6d457148"},"source":["# resnet model\n","class RESMLP(nn.Module):\n","  def __init__(self):\n","    super(RESMLP, self).__init__()\n","    # in-size 2048\n","    self.bn0 = nn.BatchNorm1d(2048)\n","    self.fc1 = nn.Linear(2048, 1024)\n","    self.bn1 = nn.BatchNorm1d(1024)\n","    self.rl1 = nn.LeakyReLU()\n","    # semantic output 1000\n","    self.fc2 = nn.Linear(1024, 1000)\n","    self.bn2 = nn.BatchNorm1d(1000)\n","    self.rl2 = nn.LeakyReLU()\n","    # output size 300\n","    self.fc3 = nn.Linear(1000, 300)\n","    self.rl3 = nn.LeakyReLU()\n","\n","  def forward(self, features):\n","    # (2048, 1024)\n","    x = self.bn0(features)\n","    x = self.fc1(x)\n","    x = self.bn1(x)\n","    x = self.rl1(x)\n","    # (1024, 1000)\n","    x = self.fc2(x)\n","    x = self.bn2(x)\n","    x = self.rl2(x)\n","    # to be removed (1000, 300)\n","    x = self.fc3(x)\n","    x = self.rl3(x)\n","    return x\n","\n","\n","# hyperparameters (the same as baseline)\n","batch_size = 256\n","learning_rate = 0.0003\n","E = 120\n","\n","# model setup\n","model = torch.load(path + 'models/res_model_tvlast.pt')\n","loss_fnc = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# data setup\n","train_set = Dataset(train_dataframe['resnet_features'].values, train_dataframe['label'].values)\n","valid_set = Dataset(valid_dataframe['resnet_features'].values, valid_dataframe['label'].values)\n","test_set = Dataset(test_dataframe['resnet_features'].values, test_dataframe['label'].values)\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n","\n","\n","# use as applicable\n","#if torch.cuda.is_available(): \n","model.cuda()\n","#\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"CHANGE\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n","# change in the training loop if need to convert to cuda\n"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RESMLP(\n","  (bn0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n","  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (rl1): LeakyReLU(negative_slope=0.01)\n","  (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n","  (bn2): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (rl2): LeakyReLU(negative_slope=0.01)\n","  (fc3): Linear(in_features=1000, out_features=300, bias=True)\n","  (rl3): LeakyReLU(negative_slope=0.01)\n",")"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"FzAUVsVa4SQH"},"source":["torch.manual_seed(0)\n","from tqdm import tqdm\n","from copy import deepcopy\n","\n","# training loop\n","epochs = []\n","trainAccu = []\n","trainLoss = []\n","validAccu = []\n","validLoss = []\n","\n","for epoch in range(100, E, 1):\n","  running_loss = 0.0\n","  running_correct = 0.0\n","  count = 0.0\n","\n","  model.train()\n","\n","  for i, data in enumerate(tqdm(train_loader, position=0)):\n","    # organize data\n","    X, y = data\n","\n","    X = torch.squeeze(X,1)\n","    X = X.type(torch.cuda.FloatTensor)\n","    y = y.type(torch.cuda.FloatTensor)\n","    # \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"CHANGE\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" IF CUDA\n","    \n","    # train\n","    optimizer.zero_grad()\n","\n","    output = model(X)\n","\n","    loss = loss_fnc(output, y)\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    # test\n","    running_loss += loss.item()*len(y)\n","    #print(output.cpu().detach().numpy().shape)\n","    #print(y.cpu().detach().numpy().shape)\n","    running_correct += accurate(output, y)\n","    count += len(y)\n","  \n","  # evaluate at every epoch\n","  trainAccu.append(running_correct/count)\n","  trainLoss.append(running_loss/count)\n","  epochs.append(epoch)\n","\n","  # evaluate validation accuracy\n","  correct, loss = evaluate(model, loss_fnc, valid_loader)\n","\n","  validAccu.append(correct)\n","  validLoss.append(loss)\n","\n","  print(\"[%3d] train loss: %.5f train accu: %f valid loss: %f valid accu: %f\" % (epoch+1, trainLoss[-1], trainAccu[-1], validLoss[-1], validAccu[-1]))\n","\n","  # save at every epoch if needed\n","  torch.save(model, path + '/models/res_model_base_' + str(epoch) + '.pt')\n","\n","  if epoch % 5 == 0:\n","    plot_result(x=deepcopy(epochs), y=[deepcopy(trainAccu), deepcopy(validAccu)], title=[\"training accuracy\", \"validation accuracy\"], x_axis=\"Epochs\", y_axis=\"Accuracy\", plot_title=\"Accuracy vs Epochs\")\n","    plot_result(x=deepcopy(epochs), y=[deepcopy(trainLoss), deepcopy(validLoss)], title=[\"training loss\", \"validation loss\"], x_axis=\"Epochs\", y_axis=\"Loss\", plot_title=\"Loss vs Epochs\")\n","\n","\n","# visualize result\n","plot_result(x=epochs, y=[trainAccu, validAccu], title=[\"training accuracy\", \"validation accuracy\"], x_axis=\"Epochs\", y_axis=\"Accuracy\", plot_title=\"Accuracy vs Epochs\")\n","plot_result(x=epochs, y=[trainLoss, validLoss], title=[\"training loss\", \"validation loss\"], x_axis=\"Epochs\", y_axis=\"Loss\", plot_title=\"Loss vs Epochs\")\n","print(\"Test accuracy and loss: \", evaluate(model, loss_fnc, test_loader))\n","\n","torch.save(model, path + '/models/res_model_base_last.pt')\n"],"execution_count":null,"outputs":[]}]}